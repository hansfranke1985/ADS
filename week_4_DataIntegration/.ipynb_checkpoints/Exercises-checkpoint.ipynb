{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class one: Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Views on databases\n",
    "\n",
    "## Creating codes on postgres\n",
    "\n",
    "## Definitions of databases!\n",
    "Movie(title, dir, year, genre)\n",
    "    Schedule(cinema, title, time)\n",
    "\n",
    "Movie(title, dir, year, genre)\n",
    "    Schedule(cinema, title, time)\n",
    "\n",
    "drop view Movie;\n",
    "drop table s1;\n",
    "drop table s2;\n",
    "drop table s3;\n",
    "drop table s4;\n",
    "\n",
    "create table s1(\n",
    "\ttitle varchar(100),\n",
    "\tdir varchar(50),\n",
    "\tyear numeric(4,0),\n",
    "\tgenre varchar(50)\n",
    ");\n",
    "\n",
    "create table s2(\n",
    "\ttitle varchar(100),\n",
    "\tdir varchar(50),\n",
    "\tyear numeric(4,0),\n",
    "\tgenre varchar(50)\n",
    ");\n",
    "\n",
    "create table s3(\n",
    "\ttitle varchar(100),\n",
    "\tdir varchar(50)\n",
    "\n",
    ");\n",
    "\n",
    "create table s4(\n",
    "\ttitle varchar(100),\n",
    "\t\tyear numeric(4,0),\n",
    "\tgenre varchar(50)\n",
    "\n",
    ");\n",
    "\n",
    "Create View Movie AS\n",
    "   SELECT * FROM S1          \n",
    "   union\n",
    "   SELECT * FROM S2          \n",
    "   union\n",
    "   SELECT S3.title, S3.dir, S4.year, S4.genre\n",
    "   FROM S3, S4                \n",
    "   WHERE S3.title = S4.title;   \n",
    "\n",
    "## insert some random data\n",
    "select * from s1\n",
    "insert into s1 values('Titanic', 'James Cameron', 1997, 'drama');\n",
    "insert into s1 values('Avatar', 'James Cameron', 2005, 'action');\n",
    "select * from Movie\n",
    "\n",
    "select * from s2\n",
    "insert into s2 values('Titanic', 'James Cameron', 1997, 'drama');\n",
    "insert into s2 values('Avatar', 'James Cameron', 2005, 'action');\n",
    "\n",
    "## Look that values insert on s3 will not present in Movie until information is inserted on s4\n",
    "select * from s3\n",
    "insert into s3 values('Amnesia', 'Guy Rich');\n",
    "insert into s3 values('Aliens', 'James Cameron');\n",
    "insert into s3 values('Dumbo', 'Tim Burton');\n",
    "select * from Movie\n",
    "\n",
    "select * from s4\n",
    "insert into s4 values('Aliens', 1986, 'action');\n",
    "insert into s4 values('Amnesia', 2015, 'drama');\n",
    "select * from Movie\n",
    "\n",
    "## Look all created views\n",
    "select * from information_schema.views\n",
    "where table_schema not in ('pg_catalog', 'information_schema')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Week 4\n",
    "Lab4 Exercises: Heterogeneous Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Question 1.\n",
    "Compute the Jaccard similarities of each pair of the following three sets: {1,\n",
    "2, 3, 4}, {2, 3, 5, 7}, and {2, 4, 6}.\n",
    "\n",
    "Question 2.\n",
    "Compute the Jaccard bag similarity of each pair of the following three bags:\n",
    "{1, 1, 1, 2}, {1, 1, 2, 2, 3}, and {1, 2, 3, 4}.\n",
    "\n",
    "Question 3.\n",
    "Let C(D1) = {aa, bb, ab , ba}, C(D2) = {aa, ac, ca, ba}, C(D3) = {ab, ba,\n",
    "ca} be the 2-shingle representation of documents D1, D2, D3. Create the\n",
    "matrix representation of the shingles-documents relationship.\n",
    "\n",
    "\n",
    "\n",
    "Question 5.\n",
    "Compute the Jaro and Jaro-Winkler similarity between arnab and urban.\n",
    "Why do you think you got this result?\n",
    "\n",
    "Question 6.\n",
    "Compute the edit distance between Recreation and Regeneration assuming\n",
    "that substitution cost is 1. What if we consider the substitution as insertion\n",
    "and deletion (cost 2)?\n",
    "\n",
    "Question 7.\n",
    "Compute the gap distance between ”Journal of Knowledge and Data Engineering” and ”J. of Knowl. and Data Eng.” assuming that the open gap cost\n",
    "= 1 and extend gap cost = 0.1.\n",
    "\n",
    "Question 8.\n",
    "Consider the following document ”need an efficient technique to group records\n",
    "if they match”. What will be the cardinality of the set that contains the 6-\n",
    "shingles of the document?\n",
    "\n",
    "Question 9.\n",
    "Use python libraries to compute three types of similarities between Journal\n",
    "and Formal.\n",
    "\n",
    "Question 10.\n",
    "Consider the shingle-document matrix that you produced in Question 3 and\n",
    "assume the following permutations:\n",
    "p1 = {aa,bb,ab,ba,ac,ca},\n",
    "p2 = {ca, ac, ba, ab, bb, aa},\n",
    "p3 = {ac, ca, ab, ba, bb, aa}.\n",
    "The hash functions are defined to be the first non-0 row of the document\n",
    "representation.\n",
    "a. Create the signature matrix of the documents.\n",
    "b. Compare the Jaccard similarity of each pair of documents with the Jaccard\n",
    "similarity of their signatures.\n",
    "\n",
    "Question 11.\n",
    "For the information to be integrated, heterogeneity can be in a set of levels.\n",
    "What are these levels?\n",
    "\n",
    "Question 12.\n",
    "Where the mappings in the information integration system are implemented\n",
    "(found)?\n",
    "\n",
    "Question 13.\n",
    "What is the pairwise Jaccard dissimilarity between C(D1), C(D2) and C(D3)\n",
    "in Question 3?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "What is the linked open data cloud?\n",
    "\n",
    "https://medium.com/virtuoso-blog/what-is-the-linked-open-data-cloud-and-why-is-it-important-1901a7cb7b1f\n",
    "\n",
    "## What is the LOD Cloud?\n",
    "The LOD Cloud is a Knowledge Graph that manifests as a Semantic Web of Linked Data. It is the natural product of several ingredients:\n",
    "- Open Standards — such as URI, URL, HTTP, HTML, RDF, RDF-Turtle (and other RDF Notations), the SPARQL Query Language, the SPARQL Protocol, and SPARQL Query Solution Document Types\n",
    "- Myriad amateur and professional Data Curators across industry and academia\n",
    "- A modern DBMS platform — Virtuoso from OpenLink Software\n",
    "- Seed Databases — initially, DBpedia and Bio2RDF formed the core; more recently, significant contributions have come from the Wikidata project and the Schema.org-dominated SEO and SSEO axis supported by Search Engine vendors (Google, Bing!, Yandex, and others) — provided master data from which other clouds (and sub-clouds) have been spawned\n",
    "The core tapestry of the LOD Cloud arises from adherence to the “deceptively simple” notion that hyperlinks should be used to identify any thing while entity→attribute→value or subject→predicate→object structured sentences should be used to describe every thing.\n",
    "The practices above constitute what are now commonly known as the principles of Linked Data — a deployment method for representations of structured data that adds the use of hyperlinks (specifically, HTTP URIs) to the EAV (Entity Attribute Value) and RDF (Resource Description Framework) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes notes: Similarities\n",
    "\n",
    "## Atomic Similarity: \n",
    "- Edit Distant => \n",
    "Number of permutations to put 2 strings the same (update, delete, insert => cost 1)\n",
    "\n",
    "- Gap Distant => \n",
    "Overcome limitatins of Edit Distant, 2 extra operations (open gap, extended gap)\n",
    "\n",
    "- Jaro => small strings . ( C= Comon char, T = transpositions/2 => \n",
    "Jaro Sim( 1/3 ( C/|s1| + C/|s2| + (C-T)/C )\n",
    "\n",
    "- Jaro-Wrinkler =>\n",
    "Formula: JaroSim + P x L x (1-JaroSim)\n",
    "Where P = scalling (0,1) \n",
    "L = Len of common prefix up to maximum 4 (!!! <font color=red>If the first letter dosent match, there is no similarity, so it will be the same as JaroSim !!!</font> \n",
    "\n",
    "- Soundex (Will not be covered)\n",
    "\n",
    "## Similarity Methods for Sets\n",
    "\n",
    "- Jackard => \n",
    "\n",
    "Similarity : sim(C1,C2) = |C1 INTERSEC C2 | / |C1 UNION C2|\n",
    "Size of the intersection divided by the size of their union\n",
    "\n",
    "distance : d(C1,C2) = 1 - |C1 INTERSEC C2 | / |C1 UNION C2|\n",
    "\n",
    "- Using Transformations:\n",
    "    1. Unary Transform (equality, stemmin, soundex, abbreviation)\n",
    "    2. N-ary transformations ( initial, prefix, suffix, substring, acronym, abbreviation)\n",
    "\n",
    "- Group Linkage\n",
    "    1. Groups of relational records\n",
    "    2. Group match when:\n",
    "        1. High similarity between individual records\n",
    "        2. Large fraction of matching records\n",
    "        \n",
    "- Facilitating Inner Relations\n",
    "    1. Problems: Heterogeneous data, improve effect by considereing data semantics\n",
    "    2. Reference reconcilition => \n",
    "    \n",
    "- Methods of Uncertain Data\n",
    "    1. General Ideas\n",
    "    2. Solutions => let probabilities on tables (linkage) , query on probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
