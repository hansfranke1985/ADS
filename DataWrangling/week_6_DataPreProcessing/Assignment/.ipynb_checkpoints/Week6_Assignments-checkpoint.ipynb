{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Week\n",
    "The goal of this assignment is to get familiar with data preparation tasks and be able to download\n",
    "and use data preparation tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1:\n",
    "Download and run as many of the following tools as possible and run them on the provided datasets:\n",
    "1. Nadeef https://github.com/daqcri/NADEEF You need to install JDK, JRE and Postgresql. In\n",
    "postgres, you need to create a user “tester” with the password the same as the user name\n",
    "and create a database “nadeef”. You can also change these options in the file nadeef.config\n",
    "in the main directory if you don’t want to create the user with this password. Download\n",
    "apache ant https://ant.apache.org/bindownload.cgi and open Windows PowerShell or\n",
    "terminal (in Linux/MAC) and change the working directory to NADEEF where you extracted\n",
    "the code from github. In the directory of NADEEF run the command ant and it will compile\n",
    "and install nadeef. If your installation is successful, then you can run the command\n",
    "(./nadeef.bat dashboard) in Windows or (./nadeef.bat dashboard) in Linux/MAC. Explore the\n",
    "tool and try to find the violation for the functional dependency first name → gender in the\n",
    "fdExample.csv file that we posted in Week 3.\n",
    "2. FAHES https://github.com/qahtanaa/pFAHES\n",
    "3. dBoost https://github.com/cpitclaudel/dBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2:\n",
    "For this task, two tables from data.gov.uk will be used to master the data preparation task. In fact,\n",
    "searching for the data is part of the data preparation; however, this task is done. The repository in\n",
    "data.gov.uk provides a set of datasets gathered in the United Kingdom from multiple organizations.\n",
    "The tables that we are going to use have been gathered from the traffic department.\n",
    "1. The data is divided over two tables, which is inconvenient for doing analysis. Using the\n",
    "merge function, merge them into one data frame using the Accident_Index field.\n",
    "2. The \"Accident_Severity\" variable needs to be recoded. You need to replace the code by:\n",
    "1=Minor, 2=Medium, 3=Severe.\n",
    "3. For a set of variables, missing values has been replaced by -1. Detect these values and report\n",
    "the names of the columns in each table that contain such values.\n",
    "4. For all variables, check if there are any clearly extreme values, or values that do not belong in\n",
    "that column. If you find any, remove these records from the dataset.\n",
    "5. Compute a variable called is_minor , that checks whether a casualty was a minor or an adult.\n",
    "Being adult is defined as having an age of 18 or above. The column should only contain the\n",
    "values ‘Yes’ and ‘No’.\n",
    "6. The 'Location_Easting_OSGR' variable has about 27 of missing values - solve this with\n",
    "imputation of the average of the 'Location_Easting_OSGR' of all records. That means,\n",
    "calculate the average of all the available values in 'Location_Easting_OSGR' and fill the\n",
    "missing cells in the column with the average value.\n",
    "7. Use FAHES to detect the disguised missing value in both tables and confirm if they are actual\n",
    "disguised values or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3:\n",
    "For this task, use the dataset pid.csv. This dataset were publicly available but it has been removed\n",
    "from the repository so use it for this assignment and don’t redistribute it. The name of the table\n",
    "and the names of the columns has been changed to anonymize the data. \n",
    "1. Remove the disguised values from the table -- We need to remove the values that equal 0\n",
    "from columns C,D and F as these are missing values but they have been disguised by the\n",
    "value 0. Remove the value but keep the record (i.e.) change the value to null\n",
    "2. Remove the Label column and remove one of the columns if their correlation is greater than\n",
    "0.6. That is, if there are two columns with correlation value > 0.6 then remove one of them\n",
    "and keep the other. The input for this step is the original dataframe not the one that has been\n",
    "produced at step 1.\n",
    "3. Use a Python or R-library to find the principal components and project the data on those\n",
    "components. Plot the projected data on the first and the second (principal components) PCs as\n",
    "a scatter plot. If you are working with R, use the (prcomp) R-function. For Python, check\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
