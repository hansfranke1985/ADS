---
title: "Assigment 1"
subtitle: "Assigment 1"
author: "Hans Franke"
date: "October 12, 2020"
output: rmarkdown::github_document
---

```{r}
library(tidyverse)
library(mice)
```


## View Data

Store the nhanes dataset from the mice package in a variable called df. Print the df variable.

```{r}
head(mice::nhanes)

df <- nhanes

view(df)
```

## Show Missing Values
Output the percentage missingness for each feature as a vector.

```{r}
is.na(df)
```


```{r}
#Missing values in all columns
colSums(is.na(df))
```

```{r}
# % of Missing values in all columns
colSums(is.na(df))/nrow(df)*100
```
## Use ggplot to show the % of the missing value

```{r}
#Put data in the DF
df_missing <- tibble(
  nmissing = colnames(is.na(df)),
  perc_col = colSums(is.na(df))/nrow(df)*100
)

df_missing
```

```{r}
#Plotting as a barplot

ggplot(df_missing, aes(x=nmissing, y = perc_col) ) +
         geom_bar(stat = "identity") +
         labs(y="% Of missing values") + 
         theme_classic()  
      
   

```

## Now display the missingness pattern per age group (1, 2, 3).

```{r}
df %>%
  group_by(age)%>%
  summarise_all(function(x) sum(is.na(x))/n()*100)%>%
  round(2)
```


## Missing Data Patterns
```{r}
md.pattern(df)
```
## Questions
1. how many rows are missing all data except the age feature? A: 7
2. how many missing values are there in the bmi feature? A: 9
3. how many rows are completely observed? A: 13
4. how many missing data patterns are there? A: 5 (we include rows without missing values as a pattern too)

```{r}
# Others packages to try :)
#install.packages("skimr")
skimr::skim(df)
```

```{r}
visdat::vis_dat(df)
```

# Assigment

## Analyze the patterns of missing data for the fdgs dataset, and write a small paragraph on how you are going to solve the missingness in this data for an analyst who wants to compute the average weight of the population under study, assuming MAR.

```{r}
#Lookinf for patterns of missing data
md.pattern(fdgs)
```

### Answer:

As we can see in the plot above, the total number of missing rows are extreme low (23 + 20 / 10030 => 0.42% ), and mainly focused on 2 variables (the others _z are only the z-score of that variable). So to consider a MAR, we should replace the values by the mean clustered by each variable, for example:
```{r}
# mean( df$wgt) and mean(df$hgt).

#Assign the fgds to a another df (dosent lose information later)
fdgs_nomiss <- fdgs

fdgs_nomiss <- within(data = fdgs_nomiss,
       expr =
         {
           wgt <- replace(x = wgt,
                           list = is.na(x = wgt),
                           values = mean(x = wgt, na.rm = TRUE) ) 
         }
       )
  
#CHECK FINAL RESULT
colSums(is.na(fdgs_nomiss))
```

```{r}
md.pattern(fdgs_nomiss)
```

But this is not the best solution because replace by the means, ads a lot of variance in the samples. The best solution should be use a regression technique to predict the value considering other variables. For example, use Age and Sex to predict the weight.

```{r}
# Lookinf visual if makes sense this correlation:

ggplot(fdgs, aes(x=age, y=wgt, color=sex)) +
  geom_point()
```
```{r}
#In fact it makes, so lets run a regression
imp <- mice(fdgs, method = "norm.predict", seed = 1,
           m = 1, print = FALSE)
xyplot(imp, wgt ~ age)
```
```{r}
#building new df

#Assign the fgds to a another df (dosent lose information later)
data_imp <- complete(imp)
mean(data_imp$wgt)
  
#CHECK FINAL RESULT
colSums(is.na(data_imp))
```

```{r}
#Comparison between methods (only on weight) => Try to see the diference in the mean( 0.380 vs 0.385)

summary(fdgs_nomiss)
```

```{r}
summary(data_imp)
```

```{r}
#Standard deviation
sd(fdgs$wgt, na.rm = TRUE) #original df
sd(fdgs_nomiss$wgt) #using mean
sd(data_imp$wgt) #using regression
```

```{r}
#Variance
var(fdgs$wgt, na.rm = TRUE) #original df
var(fdgs_nomiss$wgt) #using mean
var(data_imp$wgt) #using regression
```

